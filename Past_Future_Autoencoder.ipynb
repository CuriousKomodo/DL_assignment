{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Past_Future_Autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "vOwY2fRfVRzG",
        "jNUk3UoDJrpR",
        "g-c7V5P161XO",
        "TciOS5FbBZsM",
        "jxQxKPtx3gL9",
        "ctKL8FD3lznl",
        "Z8xpNnd-0p4X"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CuriousKomodo/DL_assignment/blob/master/Past_Future_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80WMJynJkrPQ",
        "colab_type": "code",
        "outputId": "b48a45bf-6a44-420b-d261-230a3eb3b75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import callbacks, layers, losses, models, optimizers\n",
        "from keras import backend as K\n",
        "#from visualise import *\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM,CuDNNLSTM\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Dropout\n",
        "\n",
        "dataset_path= '/content/drive/My Drive/Dataset/'\n",
        "import theano\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EmMKRWF4mjq",
        "colab_type": "code",
        "outputId": "d8a05f3a-7fa2-421c-a168-7df6ba1037be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 17:58:28.644597 140437989459840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0704 17:58:28.650498 140437989459840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0704 17:58:28.688207 140437989459840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPOZqxU4Q4rS",
        "colab_type": "code",
        "outputId": "1080db81-4ae3-4b8d-83bc-32930c1f4df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwY2fRfVRzG",
        "colab_type": "text"
      },
      "source": [
        "## Create Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MzZQ7yRHIhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "X_train = np.load(dataset_path + 'PKUMMD/X_train.npy')\n",
        "Y_train = np.load(dataset_path + 'PKUMMD/y_train.npy')\n",
        "X_val= np.load(dataset_path + 'PKUMMD/X_test.npy')\n",
        "Y_val = np.load(dataset_path + 'PKUMMD/y_val.npy')\n",
        "\n",
        "X = np.concatenate([X_train,X_val],axis=0)\n",
        "Y = np.concatenate([X_train,X_val],axis=0)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQrcWJLzUE9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "#MAYBE GET VALIDATION SET AS WELL FROM THE CURRENT TRAINING SET. \n",
        "#X = np.load(dataset_path + 'PKUMMD/X_train.npy')\n",
        "#Y = np.load(dataset_path + 'PKUMMD/y_train.npy')\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "np.save(dataset_path + 'PKUMMD/X_train.npy',X_train)\n",
        "np.save(dataset_path + 'PKUMMD/X_val.npy',X_val)\n",
        "np.save(dataset_path + 'PKUMMD/y_train.npy',y_train)\n",
        "np.save(dataset_path + 'PKUMMD/y_val.npy',y_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCetFdGBU4uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNUk3UoDJrpR",
        "colab_type": "text"
      },
      "source": [
        "# Scrap model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGB4QoArJqyy",
        "colab_type": "code",
        "outputId": "d929f26f-7a3c-4064-fb2a-93601b492159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "\n",
        "class Past_DataGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,\n",
        "                 train_data_dir=dataset_path + 'PKUMMD/X_train.npy',\n",
        "                 valid_data_dir=dataset_path + 'PKUMMD/X_val.npy',\n",
        "                 train=True,\n",
        "                 win_size=300,\n",
        "                 step_size=2,\n",
        "                 batch_size=128,\n",
        "                 shuffle=True,\n",
        "                 **kwargs):\n",
        "      \n",
        "        self.train_data_dir = train_data_dir\n",
        "        self.valid_data_dir = valid_data_dir\n",
        "        self.win_size = win_size\n",
        "        self.step_size = step_size\n",
        "        self.train=train\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.data_list = self.load_data()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.data_list) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "          data = self.data_list[idx * self.batch_size:(idx + 1) * self.batch_size] #load by batch.\n",
        "        else:\n",
        "          data = self.data_list\n",
        "        X = np.asarray(data, dtype=np.float32)\n",
        "        Y = np.flip(X, axis=1)\n",
        "        return X, Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.data_list)\n",
        "\n",
        "    def load_data(self):\n",
        "        '''\n",
        "        data_list = []\n",
        "        for f in os.listdir(self.data_dir):\n",
        "            path = os.path.join(self.data_dir, f)\n",
        "            data = np.load(path)\n",
        "            size = int((len(data) - self.win_size) / self.step_size) + 1\n",
        "            for i in range(size):\n",
        "                data_list.append(data[self.step_size * i:self.step_size * i + self.win_size])\n",
        "                '''\n",
        "        if self.train:\n",
        "          data_list = np.load(self.train_data_dir)\n",
        "        else:\n",
        "          data_list = np.load(self.valid_data_dir)\n",
        "        return data_list\n",
        "\n",
        "\n",
        "class LSTMAE(object):\n",
        "\n",
        "    def __init__(self, dim=75, hidden_units=256):\n",
        "        self.dim = dim\n",
        "        self.hidden_units = hidden_units\n",
        "        self.model = self.build()\n",
        "\n",
        "    def build(self):\n",
        "        inputs = layers.Input(shape=(None, self.dim))\n",
        "\n",
        "        encoder = layers.CuDNNLSTM(self.hidden_units, return_state=True)\n",
        "        decoder = layers.CuDNNLSTM(self.hidden_units, return_sequences=True, go_backwards=True)\n",
        "\n",
        "        en_out, en_h, en_c = encoder(inputs)\n",
        "\n",
        "        en_out = layers.Lambda(lambda x: x[:, None, :])(en_out)\n",
        "\n",
        "        de_in = layers.Lambda(lambda x: x[:, 1:, :])(inputs) \n",
        "\n",
        "        de_outs = decoder(de_in, initial_state=[en_h, en_c])\n",
        "\n",
        "        output = layers.concatenate([en_out, de_outs], 1)\n",
        "\n",
        "        out_linear = layers.TimeDistributed(layers.Dense(self.dim))\n",
        "        out = out_linear(output)\n",
        "\n",
        "        return models.Model(inputs, out)\n",
        "\n",
        "    def train(self):\n",
        "        params_train = {\n",
        "      'lr': 0.0005,'batch_size': 256, 'epochs': 30,'win_size': 600,'train':True}\n",
        "        \n",
        "        params_valid = {\n",
        "      'lr': 0.0005,'batch_size': 256, 'epochs': 30,'win_size': 600,'train':False}\n",
        "\n",
        "        self.model.compile(optimizer=optimizers.Adam(lr=params['lr']),\n",
        "                           loss=losses.mean_squared_error)\n",
        "        self.model.fit_generator(generator=DataGenerator(**params_train),\n",
        "                                 epochs=params['epochs'],validation_data = DataGenerator(**params_valid))\n",
        "\n",
        "    def predict(self, seq):\n",
        "        # seq: (bs, seq_len, dim)\n",
        "        res = self.model.predict(seq, verbose=1)\n",
        "        return res[:, ::-1, :]\n",
        "\n",
        "\n",
        "#train_X = np.load(dataset_path +'X_train.npy')\n",
        "\n",
        "ae = LSTMAE(hidden_units=512)\n",
        "ae.train()\n",
        "X_test = np.load(dataset_path + 'PKUMMD/X_test.npy')\n",
        "pred = ae.predict(X_test)\n",
        "\n",
        "\n",
        "def mse(X, Y, axis=None):\n",
        "  return (np.square(Y-X)).mean(axis=axis)\n",
        "\n",
        "loss = mse(pred.squeeze(), X_test.squeeze(), axis=0)\n",
        "\n",
        "#for example in list_examples_visualise:\n",
        "#    visualizing_prediction(X_test_target, pred_test, example)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-69273bc094ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'PKUMMD/X_test.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-173-69273bc094ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m                            loss=losses.mean_squared_error)\n\u001b[1;32m     94\u001b[0m         self.model.fit_generator(generator=DataGenerator(**params_train),\n\u001b[0;32m---> 95\u001b[0;31m                                  epochs=params['epochs'],validation_data = DataGenerator(**params_valid))\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Incompatible shapes: [256,699,75] vs. [256,698,75]\n\t [[{{node loss_5/time_distributed_6_loss/sub}}]]\n\t [[loss_5/mul/_667]]\n  (1) Invalid argument: Incompatible shapes: [256,699,75] vs. [256,698,75]\n\t [[{{node loss_5/time_distributed_6_loss/sub}}]]\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nWjvw1qSE8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(dataset_path + 'Past_AE_results/pred_test_last_10.npy',pred[-10:,:,:])\n",
        "np.save(dataset_path + 'Past_AE_results/pred_test_first_10.npy',pred[:10,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1GZVfGqkryw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load(dataset_path + 'PKUMMD/X_train.npy')\n",
        "pred_train = ae.predict(X_train)\n",
        "np.mean((pred_train - X_train)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Dvo3aTJuCw",
        "colab_type": "text"
      },
      "source": [
        "# My Past AE Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVfsOZUNuMed",
        "colab_type": "text"
      },
      "source": [
        "### Presort sequence - similar lengths batch, NOT WORKING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXY94GA2ubpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lengths = np.sum(np.sign(np.sum(np.sign(X_train),axis=-1)),axis=-1)\n",
        "idx = range(X_train.shape[0])\n",
        "Z = [x for _,x in sorted(zip(lengths,idx))]\n",
        "X_train_reordered = X_train[Z[100:],:,:] #short fix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rryokz1yVhuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lengths.sort()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsMiQrLpV5KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81429995-85f2-46fb-bea9-96268c9c8f3a"
      },
      "source": [
        "lengths[100:]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 17.,  18.,  18., ..., 652., 694., 699.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkcL4rbvd2bW",
        "colab_type": "text"
      },
      "source": [
        "### K fold validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX5refUFd3_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def load_data():\n",
        "    # load your data using this function\n",
        "\n",
        "def create model():\n",
        "    # create your model using this function\n",
        "\n",
        "def train_and_evaluate__model(model, data_train, labels_train, data_test, labels_test):\n",
        "    model.fit...\n",
        "    # fit and evaluate here.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    n_folds = 10\n",
        "    data, labels, header_info = load_data()\n",
        "    skf = StratifiedKFold(labels, n_folds=n_folds, shuffle=True)\n",
        "\n",
        "    for i, (train, test) in enumerate(skf):\n",
        "        print \"Running Fold\", i+1, \"/\", n_folds\n",
        "        model = None # Clearing the NN.\n",
        "        model = create_model()\n",
        "        train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJhcR77gd4Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_KdAQWvd4Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeBYap82J76h",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naxCLISyWr-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "from keras.layers import LSTM,CuDNNLSTM\n",
        "      \n",
        "class Past_DataGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,\n",
        "                 train_data_dir=dataset_path + 'PKUMMD/X_train.npy',\n",
        "                 valid_data_dir=dataset_path + 'PKUMMD/X_val.npy',\n",
        "                 train=True,\n",
        "                 batch_size=128,\n",
        "                 shuffle=True,\n",
        "                 sort_batch_lengths = False, #can only be set to true when shuffle=False. \n",
        "                 **kwargs):\n",
        "      \n",
        "        self.train_data_dir = train_data_dir\n",
        "        self.valid_data_dir = valid_data_dir\n",
        "        self.train=train\n",
        "        self.sort_batch_lengths = sort_batch_lengths \n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.data_list = self.load_data()\n",
        "        \n",
        "        #self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.data_list) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "          data = self.data_list[idx * self.batch_size:(idx + 1) * self.batch_size] #load by batch.\n",
        "          \n",
        "          if self.sort_batch_lengths:\n",
        "            lengths_batch = self.lengths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "            #print(lengths_batch)\n",
        "            max_length = lengths_batch.max()\n",
        "            data = data[:,:int(max_length),:]\n",
        "          \n",
        "        else:\n",
        "          data = self.data_list\n",
        "        \n",
        "        X = np.asarray(data, dtype=np.float32)\n",
        "        Y = np.flip(X, axis=1)\n",
        "        return X, Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.data_list)\n",
        "\n",
        "    def load_data(self):\n",
        "        if self.train:\n",
        "          data_list = np.load(self.train_data_dir)\n",
        "          \n",
        "          if self.sort_batch_lengths:\n",
        "            lengths = np.sum(np.sign(np.sum(np.sign(data_list),axis=-1)),axis=-1)\n",
        "            idx = range(data_list.shape[0])\n",
        "            Z = [x for _,x in sorted(zip(lengths,idx))] #indices. \n",
        "            data_list = data_list[Z[100:],:,:] #short fix, so sequences sorted ascendingly.  \n",
        "            lengths.sort()\n",
        "            self.lengths =lengths[100:] #only crop sequences long enough\n",
        "\n",
        "        else:\n",
        "          data_list = np.load(self.valid_data_dir)\n",
        "          \n",
        "        return data_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77eaOqqxkr1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://gist.github.com/jovianlin/51b1c03851221c8ae46e5a8953239cc3\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "class past_LSTM_autoencoder(object):\n",
        "  \n",
        "    def __init__(self, input_dim=75, latent_dim=256,concat_h=True, conditional = False, lr = 0.0005, epochs=3, dropout_rate=0.05):\n",
        "        self.valid_data_dir = dataset_path + 'PKUMMD/X_val.npy',\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim  = latent_dim \n",
        "        self.concat_h = concat_h\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.conditional = conditional\n",
        "        self.build_model()\n",
        "        self.x_val = self.load_validation_data()\n",
        "        self.target_val = np.flip(self.x_val, axis=1)\n",
        "        #self.dropout_rate = dropout_rate\n",
        "        \n",
        "\n",
        "    def build_model(self):\n",
        "        poses = Input(shape=(None, self.input_dim))\n",
        "        encoder = CuDNNLSTM(self.latent_dim, return_state=True)\n",
        "        decoder = CuDNNLSTM(self.latent_dim, return_sequences=True, go_backwards=True)\n",
        "        \n",
        "        encoder_outputs, state_h, state_c = encoder(poses)\n",
        "        encoder_states = [state_h, state_c] ## the last state? \n",
        "        en_out = layers.Lambda(lambda x: x[:, None, :])(encoder_outputs) #reshape to (?,1,latent_dim)\n",
        "        \n",
        "        decoder_inputs = layers.Lambda(lambda x: x[:, 1:,:])(poses) \n",
        "        decoder_outputs = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "        \n",
        "        if self.concat_h:\n",
        "          ts_dense_inputs = layers.concatenate([en_out, decoder_outputs], 1)\n",
        "        else:\n",
        "          ts_dense_inputs = decoder_outputs\n",
        "        \n",
        "        \n",
        "        ts_dense = layers.TimeDistributed(layers.Dense(self.input_dim))\n",
        "        ts_dense_inputs = Dropout(0.1)(ts_dense_inputs)\n",
        "        pred = ts_dense(ts_dense_inputs)\n",
        "\n",
        "        self.model = Model(poses, pred)\n",
        "        self.enc_model = Model(poses, en_out)\n",
        "  \n",
        "    \n",
        "    def load_validation_data(self):\n",
        "        data_val= np.load(dataset_path + 'PKUMMD/X_val.npy')\n",
        "        return data_val\n",
        "      \n",
        "    def train(self):\n",
        "      params_train = {'train':True}\n",
        "        \n",
        "      params_valid = {'train':False}\n",
        "      \n",
        "      self.model.compile(optimizer=optimizers.Adam(lr=self.lr),loss=losses.mean_squared_error)\n",
        "      history_callback =self.model.fit_generator(generator=Past_DataGenerator(**params_train),\n",
        "                                 epochs=self.epochs,validation_data = Past_DataGenerator(**params_valid))\n",
        "      \n",
        "      self.loss_history = history_callback.history[\"loss\"]\n",
        "      self.val_loss_history = history_callback.history['val_loss']\n",
        "      #self.history = history\n",
        "      #self.model_checkpoint = model_checkpoint\n",
        "        \n",
        "    def obtain_hidden(self, x, layer_idx):\n",
        "      hidden_layers = keras.backend.function(\n",
        "        [self.model.layers[0].input],  # we will feed the function with the input of the first layer\n",
        "        [self.model.layers[layer_idx].output[0]] # we want to get the output of the second layer\n",
        "        )\n",
        "      h_past = hidden_layers([x])\n",
        "      return h_past\n",
        "    \n",
        "    def predict(self, test_seq):\n",
        "        pred = self.model.predict(test_seq, verbose=1)\n",
        "        return pred[:, ::-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfRCqqfjmdU8",
        "colab_type": "code",
        "outputId": "321e131d-de4b-4f95-bc8b-d79cefaf5a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#tf.keras.backend.clear_session()\n",
        "past_ae = past_LSTM_autoencoder()\n",
        "past_ae.train()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "13/13 [==============================] - 4s 321ms/step - loss: 0.0117 - val_loss: 0.0022\n",
            "Epoch 2/3\n",
            "13/13 [==============================] - 3s 231ms/step - loss: 0.0032 - val_loss: 0.0016\n",
            "Epoch 3/3\n",
            "13/13 [==============================] - 3s 232ms/step - loss: 0.0023 - val_loss: 0.0013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dxiRETDbsBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ae91849-7751-46c8-973f-240f8464ef3b"
      },
      "source": [
        "past_ae.loss_history"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.011721304653642269, 0.0031719741662247824, 0.002300037429309808]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLn_QsmwcAVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f233e1c5-9094-4b03-c704-258d8eba6d57"
      },
      "source": [
        "past_ae.val_loss_history"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0022013885900378227, 0.0015981771284714341, 0.001252068323083222]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD88FlwbfcLJ",
        "colab_type": "code",
        "outputId": "c5f38c3a-b5c6-49bd-c03d-c377794221b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "past_ae.enc_model.save(dataset_path+'models/keras_past_model_hidden.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "past_ae.model.save(dataset_path+'models/keras_past_model_pred.h5')  # creates a HDF5 file 'my_model.h5'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer cu_dnnlstm_6 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'cu_dnnlstm_5/strided_slice_16:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'cu_dnnlstm_5/strided_slice_17:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ybqS2nGaYYc",
        "colab_type": "text"
      },
      "source": [
        "## Predict with current past AE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coe4T_PbRQGM",
        "colab_type": "code",
        "outputId": "2d850843-4359-4d56-92fe-40d7582f4ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#slightly overfitted. \n",
        "#X_test = np.load(dataset_path + 'PKUMMD/X_test.npy')\n",
        "pred = past_ae.model.predict(X_test,verbose=1)\n",
        "X_test_target = X_test.copy()\n",
        "X_test_target = X_test.copy()\n",
        "X_test_target= X_test_target[:,::-1,:]\n",
        "np.mean((pred - X_test_target[:,:,:])**2)\n",
        "np.save(dataset_path+'Past_AE_results/examples_10_test.npy',X_test[:10,:,:])\n",
        "np.save(dataset_path+'Past_AE_results/preds_10_test.npy',pred[:10,::-1,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "452/452 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gcnbJ8Heq4B",
        "colab_type": "code",
        "outputId": "d9b13954-94c2-4d40-d89e-4427f8582c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean((pred - X_test_target[:,:,:])**2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0007946149443881862"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgTDib4aZZUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = past_ae.model.predict(X_train[:100,:,:])\n",
        "X_train_target = X_train.copy()\n",
        "X_train_target = X_train[:100,:,:].copy()\n",
        "X_train_target= X_train_target[:100,::-1,:]\n",
        "np.mean((pred - X_train_target[:100,:,:])**2)\n",
        "\n",
        "np.save(dataset_path+'Past_AE_results/examples_10_train.npy',X_train[:10,:,:])\n",
        "np.save(dataset_path+'Past_AE_results/pred_10_train.npy',pred[:10,::-1,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TbO_AQDZz2d",
        "colab_type": "code",
        "outputId": "de7d6da4-7de9-4802-8b4c-1ed52bf813d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean((pred - X_train_target[:100,:,:])**2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0008107621693811608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbgETuftZv09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Pp2BHZQ8iE",
        "colab_type": "text"
      },
      "source": [
        "# Load past model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wimppnydXae",
        "colab_type": "code",
        "outputId": "2da9d0e9-c461-4180-8ca2-fc31a9312220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "#K.clear_session()\n",
        "#model.model.save(dataset_path+'models/keras_past_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#del model  # deletes the existing model\n",
        "past_ae_lstm = load_model(dataset_path+'models/keras_past_model_hidden.h5')\n",
        "#past_ae_lstm = past_ae.enc_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-c7V5P161XO",
        "colab_type": "text"
      },
      "source": [
        "# Future VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY_O8BLL-Uoc",
        "colab_type": "code",
        "outputId": "f8015bac-604c-4460-ec72-cc82bac88f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_val = np.load(dataset_path + 'PKUMMD/X_test.npy')\n",
        "h_val = past_ae_lstm.predict(X_val)\n",
        "h_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452, 1, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWas949veC5m",
        "colab_type": "code",
        "outputId": "c0cec314-6097-46c8-d2ae-f23d47745f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(np.arange(10,699,10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycyjFss0-O3o",
        "colab_type": "text"
      },
      "source": [
        "### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKD507Wp-RPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generates inputs for encoder: which is concat of future poses with past information. \n",
        "#Also generates target, which is a few poses in future. \n",
        "#Set to one step for now, while h_past is computed from t>10\n",
        "\n",
        "class future_generator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,\n",
        "                 train_data_dir=dataset_path + 'PKUMMD/X_train.npy',\n",
        "                 #past_ae_dir = dataset_path+'models/keras_past_model_hidden.h5',\n",
        "                 past_ae_model = None,\n",
        "                 past_hidden_dim = 256,\n",
        "                 elem_dim=75,\n",
        "                 step_size = 2,\n",
        "                 batch_size=128,\n",
        "                 shuffle=True,\n",
        "                 n_poses_predict = 1, \n",
        "                 timestep = 10,\n",
        "                 time_start = 10,\n",
        "                 **kwargs):\n",
        "        \n",
        "        self.train_data_dir = train_data_dir\n",
        "        self.past_hidden_dim = past_hidden_dim\n",
        "        self.timestep = timestep\n",
        "        self.elem_dim = elem_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.time_start = time_start\n",
        "        self.step_size = step_size\n",
        "        self.data_list = self.load_data()\n",
        "        self.past_ae = past_ae_model \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "\n",
        "    def load_past_model(self):\n",
        "        past_model = load_model(self.past_ae_dir)\n",
        "        return past_model\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.data_list) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx * self.batch_size:(idx + 1) * self.batch_size] #load by batch.\n",
        "        X = np.asarray(data, dtype=np.float32)\n",
        "        max_length=X.shape[1]\n",
        "        time_frames = np.arange(self.time_start,max_length-self.timestep, self.step_size)\n",
        "        timesteps_to_loop = len(time_frames)\n",
        "        \n",
        "        #treat each time step as a separate example\n",
        "        h_past_array = np.zeros((self.batch_size*(timesteps_to_loop+1), self.past_hidden_dim))\n",
        "        future_poses_array = np.zeros((self.batch_size*(timesteps_to_loop+1),self.timestep,self.elem_dim))\n",
        "        target_array= np.zeros((self.batch_size*(timesteps_to_loop+1),self.elem_dim))\n",
        "        \n",
        "        for i in range(len(time_frames)): #timestep\n",
        "          # always predict one time step ahead during training\n",
        "          t = time_frames[i]\n",
        "          #print('t=',t)\n",
        "          future_poses = X[:,t:t+self.timestep,:]\n",
        "          past_poses = X[:,:t,:]\n",
        "          if self.past_ae:\n",
        "            h_past = self.past_ae.predict(past_poses)\n",
        "          else:\n",
        "            print('Need a past autoencoder model')\n",
        "          target = X[:,t,:]\n",
        "          \n",
        "          h_past_array[self.batch_size*i : self.batch_size*(i+1),:] = h_past[:,0,:]\n",
        "          future_poses_array[self.batch_size*i:self.batch_size*(i+1),:] = future_poses\n",
        "          target_array[self.batch_size*i:self.batch_size*(i+1),:] = target\n",
        "          \n",
        "        return [future_poses_array,h_past_array], target_array\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.data_list)\n",
        "\n",
        "    def load_data(self):\n",
        "        data_list = np.load(self.train_data_dir)\n",
        "        return data_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n30SnvC-vOlQ",
        "colab_type": "text"
      },
      "source": [
        "### Single Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTRzHqbd5I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_vae_loss(z_log_var, z_mean,kl_weight=0.01):\n",
        "    \"\"\"\" Wrapper function which calculates auxiliary values for the complete loss function.\n",
        "     Returns a *function* which calculates the complete loss given only the input and target output \"\"\"\n",
        "    # KL loss\n",
        "    \n",
        "    def compute_kl(z_mean, z_log_var,kl_weight):\n",
        "      kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "      kl_loss =  -0.5 * kl_weight *K.sum(kl_loss, axis=-1)\n",
        "      return kl_loss\n",
        "    \n",
        "    kl_loss = compute_kl(z_mean, z_log_var,kl_weight)\n",
        " \n",
        "    def vae_loss(y_true, y_pred):\n",
        "        md_loss = mse(y_true, y_pred)\n",
        "        model_loss = kl_loss + md_loss\n",
        "        return model_loss\n",
        "\n",
        "    return vae_loss\n",
        "  \n",
        "  \n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "  \n",
        "\n",
        "def mse(X, Y, axis=None):\n",
        "  SSE = np.square(Y-X)\n",
        "  MSE = K.mean(SSE, axis=axis)\n",
        "  return MSE\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxz0ZMYwCx6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class future_VAE(object):\n",
        "  \n",
        "    def __init__(self, hidden_dim = 256, #from past autoencoder\n",
        "                elem_dim = 75,\n",
        "                timestep = 5,\n",
        "                latent_dim = 128,\n",
        "                epochs = 5,\n",
        "                enc_intermediate_dim  = 256,\n",
        "                dec_intermediate_dim = 256,\n",
        "                lr = 0.001,\n",
        "                kl_weight = 0.01\n",
        "                ):\n",
        "    \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.elem_dim = elem_dim\n",
        "        self.epochs = epochs\n",
        "        self.enc_intermediate_dim = enc_intermediate_dim\n",
        "        self.dec_intermediate_dim = dec_intermediate_dim\n",
        "        self.past_ae = None\n",
        "        self.timestep = timestep\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.kl_weight= kl_weight\n",
        "        self.build_model()\n",
        "        \n",
        "\n",
        "    def build_model(self):\n",
        "      \n",
        "        future_poses = Input(shape=(self.timestep, self.elem_dim), name='future_poses') #fixed time step ahead.\n",
        "        h_past = Input(shape=(self.hidden_dim,), name='h_past')\n",
        "        future_poses_r = layers.Lambda(lambda x: x[:, :,:])(future_poses) \n",
        "        future_poses_r = layers.Reshape((self.timestep*self.elem_dim,))(future_poses_r)\n",
        "\n",
        "        # future encoder, but discarded in testing. \n",
        "        enc_inputs = layers.concatenate([h_past,future_poses_r] ,1) #so dimension = (?, hidden_layer + timesteps * 75 )\n",
        "        enc_l1 = Dense(enc_intermediate_dim, activation='relu')(enc_inputs)\n",
        "        self.z_mean = Dense(latent_dim, name='z_mean')(enc_l1)\n",
        "        self.z_log_var = Dense(latent_dim, name='z_log_var')(enc_l1)\n",
        "        z = layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([self.z_mean, self.z_log_var])\n",
        "\n",
        "        # instantiate encoder model\n",
        "        encoder = Model([future_poses,h_past], [self.z_mean, self.z_log_var, z], name='encoder')\n",
        "       \n",
        "        # future decoder\n",
        "        latent = Input(shape=(latent_dim,), name='z_sampling')\n",
        "        latent_inputs = layers.concatenate([latent,h_past] ,1) \n",
        "        \n",
        "        dec_l1 = Dense(dec_intermediate_dim, activation='relu')(latent_inputs)\n",
        "        outputs = Dense(elem_dim, activation='sigmoid')(dec_l1)\n",
        "\n",
        "        # instantiate decoder model\n",
        "        decoder = Model([latent,h_past], outputs, name='decoder')\n",
        "        outputs = decoder([encoder([future_poses,h_past])[2],h_past])\n",
        "        outputs_test = decoder([latent,h_past])\n",
        "\n",
        "        vae = Model([future_poses,h_past], outputs, name='vae')\n",
        "        vae_test = Model(z, outputs_test, name='vae_test')\n",
        "        \n",
        "        \n",
        "    def train(self):\n",
        "        vae_loss = compute_vae_loss(self.z_log_var, self.z_mean, self.kl_weight)\n",
        "        vae.compile(optimizer=optimizers.Adam(lr=lr),loss = vae_loss)\n",
        "        self.model.compile(optimizer=optimizers.Adam(self.lr),loss=losses.mean_squared_error)\n",
        "        self.model.fit_generator(generator=future_generator(past_ae_model = past_ae),\n",
        "                                 epochs=self.epochs,validation_data=([future_val, h_val[:,0,:]],target_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In-dXelxSnT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TciOS5FbBZsM",
        "colab_type": "text"
      },
      "source": [
        "### Unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgNxgVqTkyff",
        "colab_type": "text"
      },
      "source": [
        "One drawback of this approach is error drifting,\n",
        "where the prediction error of the current pose will propagate\n",
        "into the next pose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QB1TZFx4YPn",
        "colab_type": "code",
        "outputId": "8ddd9d59-8c3d-4488-df3f-13399f083ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "\n",
        "#https://keras.io/examples/variational_autoencoder/\n",
        "#https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
        "#https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n",
        "\n",
        "\n",
        "hidden_dim = 256 #from past autoencoder\n",
        "elem_dim = 75\n",
        "timestep = 10\n",
        "latent_dim = 128\n",
        "epochs = 10\n",
        "enc_intermediate_dim  = 256\n",
        "dec_intermediate_dim = 256\n",
        "lr = 0.001\n",
        "\n",
        "### Validation data\n",
        "X_val= np.load(dataset_path + 'PKUMMD/X_test.npy')\n",
        "h_val = past_ae_lstm.predict(X_val[:50,:100,:])\n",
        "future_val = X_val[:50,100:100+timestep,:]\n",
        "target_val = X_val[:50,100,:]\n",
        "####\n",
        "\n",
        "future_poses = Input(shape=(timestep, elem_dim), name='future_poses') #fixed time step ahead.\n",
        "h_past = Input(shape=(hidden_dim,), name='h_past')\n",
        "future_poses_r = layers.Lambda(lambda x: x[:, :,:])(future_poses) \n",
        "\n",
        "#future_poses_dim = future_poses.get_shape().as_list()\n",
        "future_poses_r = layers.Reshape((timestep*elem_dim,))(future_poses_r)\n",
        "#future_poses_r = tf.keras.layers.Flatten(future_poses)\n",
        "enc_inputs = layers.concatenate([h_past,future_poses_r] ,1) #so dimension = (?, hidden_layer + timesteps * 75 )\n",
        "enc_inputs = Dropout(0.1)(enc_inputs )\n",
        "enc_l1 = Dense(enc_intermediate_dim, activation='relu')(enc_inputs)\n",
        "enc_l1 = Dropout(0.1)(enc_l1)\n",
        "\n",
        "z_mean = Dense(latent_dim, name='z_mean')(enc_l1)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(enc_l1)\n",
        "z = layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model([future_poses,h_past], [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()\n",
        "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
        "\n",
        "# build decoder model\n",
        "# input: z and concat with current pose? \n",
        "latent = Input(shape=(latent_dim,), name='z_sampling')\n",
        "latent_inputs = layers.concatenate([latent,h_past] ,1) \n",
        "\n",
        "dec_l1 = Dense(dec_intermediate_dim, activation='relu')(latent_inputs)\n",
        "dec_l1 = Dropout(0.1)(dec_l1)\n",
        "\n",
        "outputs = Dense(elem_dim, activation='sigmoid')(dec_l1)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model([latent,h_past], outputs, name='decoder')\n",
        "\n",
        "outputs = decoder([encoder([future_poses,h_past])[2],h_past])\n",
        "\n",
        "#z_test = layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([tf.ones(latent_dim), tf.ones(latent_dim)])\n",
        "outputs_test = decoder([latent,h_past])\n",
        "\n",
        "vae = Model([future_poses,h_past], outputs, name='vae_mlp')\n",
        "vae_test = Model([latent,h_past], outputs_test, name='vae_test') #so this way only take \n",
        "\n",
        "vae_loss = compute_vae_loss(z_log_var, z_mean)\n",
        "#vae.add_loss()\n",
        "vae.compile(optimizer=optimizers.Adam(lr=lr),loss = vae_loss) #losses.mean_squared_error\n",
        "vae.fit_generator(generator=future_generator(past_ae_model = past_ae_lstm),epochs=epochs, \n",
        "                  validation_data=([future_val, h_val[:,0,:]],target_val))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "future_poses (InputLayer)       (None, 10, 75)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 10, 75)       0           future_poses[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "h_past (InputLayer)             (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 750)          0           lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 1006)         0           h_past[0][0]                     \n",
            "                                                                 reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 1006)         0           concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 256)          257792      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 256)          0           dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 128)          32896       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 128)          32896       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 128)          0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 323,584\n",
            "Trainable params: 323,584\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "11/11 [==============================] - 147s 13s/step - loss: 0.1915 - val_loss: 0.1113\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 144s 13s/step - loss: 0.0804 - val_loss: 0.0532\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 144s 13s/step - loss: 0.0357 - val_loss: 0.0315\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 143s 13s/step - loss: 0.0202 - val_loss: 0.0231\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 143s 13s/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 143s 13s/step - loss: 0.0086 - val_loss: 0.0114\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 143s 13s/step - loss: 0.0056 - val_loss: 0.0083\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 143s 13s/step - loss: 0.0039 - val_loss: 0.0070\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 142s 13s/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 142s 13s/step - loss: 0.0023 - val_loss: 0.0059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0bf8f9f2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5BXrQ5cJ4HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae.save(dataset_path+'models/keras_vae_model2.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaseasTScoV4",
        "colab_type": "code",
        "outputId": "75d19650-6d5a-49df-f133-5489acd51e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test= np.load(dataset_path + 'PKUMMD/X_test.npy')\n",
        "h_test = past_ae_lstm.predict(X_test[:,:100,:])\n",
        "pred =vae.predict([X_test[:,100:110,:],h_test[:,0,:]]) #want to predict the 10th action\n",
        "loss = np.mean((pred-X_test[:,100,:])**2)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004285243954252144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbjaBLMaFYuC",
        "colab_type": "code",
        "outputId": "8ec51dbb-9338-45e0-c601-68c23f510102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train= np.load(dataset_path + 'PKUMMD/X_train.npy')\n",
        "h_train= past_ae_lstm.predict(X_train[:,:100,:])\n",
        "pred =vae.predict([X_train[:,100:110,:],h_train[:,0,:]]) #want to predict the 10th action\n",
        "loss = np.mean((pred-X_train[:,100,:])**2)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005694899873231995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxQxKPtx3gL9",
        "colab_type": "text"
      },
      "source": [
        "### Predict future poses recursively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joLVmh3OKHri",
        "colab_type": "code",
        "outputId": "7ccb15a3-73b8-435c-a2a1-7e8e5cafe1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#We know the future.. still in a training environment. \n",
        "#now predict poses recursively for the nex...\n",
        "n_pred = 50\n",
        "n_start = 10\n",
        "short_target_obs = X_test[:10,n_start,:]\n",
        "long_target_obs = X_test[:10,:n_start+n_pred,:]\n",
        "long_prediction = np.zeros_like(X_test[:10,: n_start + n_pred, :])\n",
        "print(long_prediction.shape)\n",
        "#fill the prediction sequence with past observation up to starting point. \n",
        "long_prediction[:,:n_start,:] = X_test[:10,:n_start,:]\n",
        "\n",
        "for t in np.arange(n_start,n_start+n_pred):\n",
        "  past_obs = X_test[:10,:t,:]\n",
        "  future_obs = X_test[:10,t:t+10,:]\n",
        "  h_test = past_ae_lstm.predict(past_obs)\n",
        "  pred =vae.predict([future_obs,h_test[:,0,:]])\n",
        "  past_obs = np.concatenate([past_obs,pred.reshape(10,1,75)], axis=1)\n",
        "  long_prediction[:,t,:] = pred\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 60, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZBX_beD8C3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_time = np.mean((long_target_obs[:,n_start:,:] - long_prediction[:,n_start:,:])**2, axis=(0,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azSzYa0R_weu",
        "colab_type": "code",
        "outputId": "ef69bfa0-4124-40b1-9e74-57552d2a5cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(range(n_pred),MSE_time)\n",
        "plt.title('MSE of predicted pose over time, for n_start = 10')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MSE of predicted pose over time, for n_start = 10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9BVFUbIIFX1FUZQs4v8DagyWMJEo88UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3wpwQZO_Cgj",
        "colab_type": "code",
        "outputId": "c94b8edb-801a-40aa-ef2e-5e39dd2afc18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MSE = np.mean((long_target_obs[:,n_start:,:] - long_prediction[:,n_start:,:] )**2)\n",
        "MSE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01949357261188715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pET6_Jdb9-IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We know the future.. still in a training environment. \n",
        "#now predict poses recursively for the nex...\n",
        "n_pred = 50\n",
        "n_start = 50\n",
        "short_target_obs = X_test[:10,n_start,:]\n",
        "long_target_obs = X_test[:10,:n_start+n_pred,:]\n",
        "long_prediction = np.zeros_like(X_test[:10,: n_start + n_pred, :])\n",
        "#fill the prediction sequence with past observation up to starting point. \n",
        "long_prediction[:,:n_start,:] = X_test[:10,:n_start,:]\n",
        "\n",
        "#h_test = past_ae_lstm.predict(past_obs)\n",
        "#pred =vae.predict([future_obs,h_test[:,0,:]])\n",
        "#past_obs = np.concat(past_obs,pred, axis=1) #append the last prediction as past observation\n",
        "\n",
        "for t in np.arange(n_start,n_start+n_pred):\n",
        "  past_obs = X_test[:10,:t,:]\n",
        "  future_obs = X_test[:10,t:t+10,:]\n",
        "  h_test = past_ae_lstm.predict(past_obs)\n",
        "  pred =vae.predict([future_obs,h_test[:,0,:]])\n",
        "  past_obs = np.concatenate([past_obs,pred.reshape(10,1,75)], axis=1)\n",
        "  long_prediction[:,t,:] = pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gYStm2W9-5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_time = np.mean((long_target_obs[:,n_start:,:] - long_prediction[:,n_start:,:] )**2, axis=(0,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2M2SkBY--HI",
        "colab_type": "code",
        "outputId": "80b74690-215e-4b3b-b1ff-dfdb942289c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean((long_target_obs[:,n_start:,:] - long_prediction[:,n_start:,:] )**2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008530360319874312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl7UuQQSAD7X",
        "colab_type": "code",
        "outputId": "88b8b697-5d31-4741-e2ce-76384ce516da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(range(n_pred),MSE_time)\n",
        "plt.title('MSE of predicted pose over time, for n_start = 10')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MSE of predicted pose over time, for n_start = 10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F0EvjZ5A-Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(dataset_path+'future_target_10_test_nstart_50.npy',long_target_obs[:,n_start:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM0kPUl1BHGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(dataset_path+'futre_pred_10_test_nstart_10.npy',long_prediction[:,n_start:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VJttdXl9-9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.mean((long_target_obs[0,n_start:,:] - long_prediction[0,n_start:,:])**2,axis=(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctKL8FD3lznl",
        "colab_type": "text"
      },
      "source": [
        "# Dropout Autoencoder - Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LM6n5ibqh2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://bitbucket.org/parthaEth/humanposeprediction/src/ERD/python_models/EvaluateAutoEncoder/DropOutJointsExpt.py\n",
        "def expandToAll3AxisIndices(index_list):\n",
        "  #assuming the pose data is 25 x 3 not 3 x 25! \n",
        "    expanded_list = []\n",
        "    for idx in index_list:\n",
        "        for i in range(3):\n",
        "            expanded_list.append((i*25)+idx)\n",
        "    return expanded_list\n",
        "  \n",
        "  \n",
        "def expandToAll3AxisIndices_old(index_list):\n",
        "  #assuming the pose data is 25 x 3 not 3 x 25! \n",
        "    expanded_list = []\n",
        "    for idx in index_list:\n",
        "        for i in range(3):\n",
        "            expanded_list.append((idx-1) * 3 + i)\n",
        "    return expanded_list\n",
        "  \n",
        "  \n",
        "def random_select_2D(batch_num,dropout_rate):\n",
        "  joint_num = 25\n",
        "  num_to_drop = int(dropout_rate*joint_num)\n",
        "  index_array = np.random.randint(joint_num, size=(batch_num,num_to_drop))\n",
        "  return index_array\n",
        "\n",
        "def random_select(dropout_rate):\n",
        "  joint_num = 25\n",
        "  num_to_drop = int(dropout_rate*joint_num)\n",
        "  index_array = np.random.randint(joint_num, size=(num_to_drop))\n",
        "  return index_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ajHrtKxg8gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generates inputs for encoder: which is concat of future poses with past information. \n",
        "#Also generates target, which is a few poses in future. \n",
        "#Set to one step for now, while h_past is computed from t>10\n",
        "\n",
        "class dae_generator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,\n",
        "                 train_data_dir=dataset_path + 'PKUMMD/X_train.npy',\n",
        "                 valid_data_dir=dataset_path + 'PKUMMD/X_val.npy',\n",
        "                 batch_size=128,\n",
        "                 shuffle=True,\n",
        "                 corrupt=True,\n",
        "                 train = True,\n",
        "                 dropout_rate = 0.5):\n",
        "\n",
        "        self.train_data_dir = train_data_dir\n",
        "        self.valid_data_dir = valid_data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.train = train \n",
        "        self.data_list = self.load_data()\n",
        "        self.on_epoch_end()\n",
        "        self.corrupt = corrupt\n",
        "        self.dropout_rate = dropout_rate #or create some sort of schedule... \n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(len(self.data_list) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      data = self.data_list[idx * self.batch_size:(idx + 1) * self.batch_size] #load by batch.\n",
        "      target = np.zeros((data.shape[0]* data.shape[1],data.shape[-1]))\n",
        "      filtered = np.zeros((data.shape[0]* data.shape[1],data.shape[-1]))\n",
        "\n",
        "      #loop by timestep, return each frame through time by batch. \n",
        "      for t in range(data.shape[1]):\n",
        "        X_original = np.asarray(data[:,t,:], dtype=np.float32)\n",
        "\n",
        "        #define a data generator\n",
        "        index_array = random_select(self.dropout_rate) #or do an array... \n",
        "        dropout_idx = expandToAll3AxisIndices(index_array)\n",
        "        X_filtered = np.array(X_original)\n",
        "\n",
        "        ## drop by letting it be 0\n",
        "        ## train by dropping the same joint per batch? \n",
        "        if self.corrupt:\n",
        "          X_filtered[:,dropout_idx] = 0\n",
        "        else:\n",
        "          range_scale = 0.4\n",
        "          X_filtered[:, dropout_idx] += np.random.uniform(low=-range_scale, high=range_scale,size=len(dropout_idx))\n",
        "\n",
        "        #print('t=',t)\n",
        "        target[t*self.batch_size:(t+1)*self.batch_size,:] = X_original \n",
        "        filtered[t*self.batch_size:(t+1)*self.batch_size,:] = X_filtered\n",
        "\n",
        "\n",
        "        return filtered, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.data_list)\n",
        "\n",
        "    def load_data(self):\n",
        "        if self.train:\n",
        "          data_list = np.load(self.train_data_dir)\n",
        "        else:\n",
        "          data_list = np.load(self.valid_data_dir)\n",
        "        #But instead, reshape such that each frame is one example!\n",
        "        #data_list = data.reshape(data.shape[0]*data.shape[1], data.shape[-1])\n",
        "        return data_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg_hUo23yTbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DAE(object):\n",
        "  \n",
        "    def __init__(self, hidden_dim = 256, #from past autoencoder\n",
        "                elem_dim = 75,\n",
        "                epochs = 8,\n",
        "                lr = 0.001,\n",
        "                 **kwargs):\n",
        "    \n",
        "        self.valid_data_dir = dataset_path + 'PKUMMD/X_train.npy'\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.elem_dim = elem_dim\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        dropout_poses = Input(shape=(self.elem_dim,), name='dropout_poses')\n",
        "        l1 = Dense(self.hidden_dim,activation='relu')(dropout_poses)\n",
        "        #drop_l1 = tf.layers.dropout(inputs = l1,rate=0.2)\n",
        "        #print('dropoute')\n",
        "        l2 = Dense(self.hidden_dim,activation='relu')(l1)\n",
        "        #drop_l2 = Dropout(rate=0.2)\n",
        "        #drop_l2 = tf.layers.dropout(inputs = l2,rate=0.2)\n",
        "        l3 = Dense(self.hidden_dim,activation='relu')(l2)\n",
        "        #drop_l3 = tf.layers.dropout(inputs = l3,rate=0.2)\n",
        "        recon_poses = Dense(self.elem_dim)(l3)\n",
        "        self.model = Model(dropout_poses, recon_poses, name='dae')\n",
        "\n",
        "    def train(self):\n",
        "        params_train = {'shuffle': True,'train':True}\n",
        "        params_val = {'shuffle': False,'train':False}\n",
        "        self.model.compile(optimizer=optimizers.Adam(lr=self.lr),loss = losses.mean_squared_error) \n",
        "        self.model.fit_generator(generator=dae_generator(**params_train),epochs=self.epochs,validation_data=dae_generator(**params_val))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ngtQYndQjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlNft_6y4E-s",
        "colab_type": "code",
        "outputId": "136a4fbb-eee9-4f94-a4c9-465730e64a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "dae = DAE()\n",
        "dae.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 10:08:36.870774 139693775861632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "11/11 [==============================] - 5s 496ms/step - loss: 3.0087e-04 - val_loss: 1.0589e-04\n",
            "Epoch 2/8\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 6.3946e-05 - val_loss: 2.2998e-05\n",
            "Epoch 3/8\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 2.8846e-05 - val_loss: 2.1026e-05\n",
            "Epoch 4/8\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 1.9725e-05 - val_loss: 1.7806e-05\n",
            "Epoch 5/8\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 1.7160e-05 - val_loss: 2.2542e-05\n",
            "Epoch 6/8\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 1.3789e-05 - val_loss: 1.3395e-05\n",
            "Epoch 7/8\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 1.4956e-05 - val_loss: 1.0784e-05\n",
            "Epoch 8/8\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 1.1169e-05 - val_loss: 1.1519e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt-nEnZbHDnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "#K.clear_session()\n",
        "dae.model.save(dataset_path+'models/keras_dae_model.h5')  # creates a HDF5 file 'my_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8xpNnd-0p4X",
        "colab_type": "text"
      },
      "source": [
        "### unstructured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssZIFS1Ql6Ci",
        "colab_type": "code",
        "outputId": "9b1073b4-dfe7-4b3d-8ae2-a92cb48ff2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#trained seperately? on stationary poses? \n",
        "#article suggested three 3000-size dense layers!! with annealing dropout rate from 0.5\n",
        "K.clear_session()\n",
        "elem_dim = 75\n",
        "hidden_dim = 500 \n",
        "lr = 0.001\n",
        "#original_poses = Input(shape=(elem_dim,), name='original_poses') #fixed time step ahead.\n",
        "\n",
        "epochs = 5\n",
        "dropout_rate = 0.2\n",
        "\n",
        "dropout_poses = Input(shape=(elem_dim,), name='dropout_poses')\n",
        "drop_l1 = Dense(hidden_dim,activation='relu')(dropout_poses)\n",
        "drop_l2 = Dense(hidden_dim,activation='relu')(drop_l1)\n",
        "drop_l3 = Dense(hidden_dim,activation='relu')(drop_l2)\n",
        "recon_poses = Dense(elem_dim)(drop_l3)\n",
        "\n",
        "dae = Model(dropout_poses, recon_poses, name='dae')\n",
        "dae.compile(optimizer=optimizers.Adam(lr=lr),loss = losses.mean_squared_error) \n",
        "dae.fit_generator(generator=dae_generator(),epochs=epochs)#validation_data=(x_val, x_val)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.0087\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0014\n",
            "Epoch 3/5\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 7.9368e-04\n",
            "Epoch 4/5\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 5.0673e-04\n",
            "Epoch 5/5\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 3.9211e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1975f18b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je0-k1FYt5Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btlGJl1rvRhS",
        "colab_type": "text"
      },
      "source": [
        "# Future VAE LSTM - Not done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOsgmx5qvTyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gRYA8eXzj_x",
        "colab_type": "text"
      },
      "source": [
        "# Future VQ-VAE - Not done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7IqWWyBzlyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}